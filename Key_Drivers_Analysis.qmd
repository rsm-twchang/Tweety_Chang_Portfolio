---
title: "Key Drivers Analysis"
format: html
author: "Tweety"
date: "2025-06-06"
callout-appearance: minimal
---

## Introduction

Clustering helps reveal patterns when there is no target variable to predict. Here, K-Means is used to explore the [Palmer Penguins](https://www.kaggle.com/datasets/parulpandey/palmer-archipelago-antarctica-penguin-data) dataset through two measurements—**bill length** and **flipper length**—to see whether the data naturally separates into distinct groups **without using species labels**. After forming clusters, we compare them back to the species categories to check how well morphology alone reflects biological differences.

K-Means is an **unsupervised** method that assigns each observation to one of `k` clusters by minimizing within-cluster variation. Because the result depends on the choice of `k` and on initialization, it is useful to inspect how the algorithm evolves and to evaluate multiple cluster counts rather than relying on a single run.

This page includes a from-scratch implementation alongside the `scikit-learn` version, visualizes centroid updates across iterations, and uses **WCSS** and **silhouette score** to guide the choice of `k`.

-----

## Objective

The objective of this analysis is to apply K-Means clustering to the *Palmer Penguins* dataset using **bill length** and **flipper length**, and to examine whether these two measurements alone reveal meaningful structure without using species labels. To make the method transparent, K-Means is implemented both **from scratch** and with `scikit-learn`, and the results are compared in terms of centroid locations and cluster assignments. We also visualize how centroids and memberships change across iterations to understand convergence behavior. Finally, we evaluate multiple values of `k` using **within-cluster sum of squares (WCSS)** and **silhouette score**, then interpret the selected clustering by comparing groups back to species categories after the clustering step.

-----

## Data Description

This project uses the *Palmer Penguins* dataset. Each row represents one observed penguin and includes metadata (species, island, sex, year) plus physical measurements recorded in standard units.

### Variables

- `species`: Adélie, Chinstrap, or Gentoo  
- `island`: island of observation  
- `bill_length_mm`: bill length (mm)  
- `bill_depth_mm`: bill depth (mm)  
- `flipper_length_mm`: flipper length (mm)  
- `body_mass_g`: body mass (g)  
- `sex`: recorded biological sex (when available)  
- `year`: observation year  

### Features used for clustering

K-Means is fit using two continuous features:

- **Bill length (`bill_length_mm`)**
- **Flipper length (`flipper_length_mm`)**

Species is not used during clustering; it is used afterward to interpret how clusters align with known categories.
```{python}
#| echo: false
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
```
```{python}
#| echo: false
penguins = pd.read_csv("palmer_penguins.csv")
penguins.head()
```

::: {.callout-note collapse="true"}
### Data Preview (first 5 rows)

| species | island     | bill_length_mm | bill_depth_mm | flipper_length_mm | body_mass_g | sex    | year |
|----------|------------|----------------|---------------|-------------------|-------------|--------|------|
| Adelie   | Torgersen  | 39.1 | 18.7 | 181 | 3750 | male   | 2007 |
| Adelie   | Torgersen  | 39.5 | 17.4 | 186 | 3800 | female | 2007 |
| Adelie   | Torgersen  | 40.3 | 18.0 | 195 | 3250 | female | 2007 |
| Adelie   | Torgersen  | 36.7 | 19.3 | 193 | 3450 | female | 2007 |
| Adelie   | Torgersen  | 39.3 | 20.6 | 190 | 3650 | male   | 2007 |

:::

## K-Means Clustering

### Selecting the Number of Clusters

**Figure 1. Custom K-Means — Iteration 1**
![Figure 1. Custom K-Means — Iteration 1](figures/fig_kmeans_iter1.png){#fig_kmeans_iter1}

With randomly initialized centroids, clusters are still loosely defined and several regions overlap, especially in the middle of the plot. The centroid markers show starting positions that do not yet match the densest parts of the data.

**Figure 2. Custom K-Means — Iteration 2**
![Figure 2. Custom K-Means — Iteration 2](figures/fig_kmeans_iter2.png){#fig_kmeans_iter2}

After one update, centroids shift sharply toward high-density areas and the cluster boundaries become more coherent. Most of the separation emerges here, with a clearer split between the high–flipper-length group and the two lower bands.

**Figure 3. Custom K-Means — Final clustering (Iteration 10)**  
![Figure 3. Custom K-Means — Final clustering (Iteration 10)](figures/fig_kmeans_iter10.png){#fig-kmeans-final}

Iteration 10 represents the converged solution. Centroid movement is negligible relative to earlier iterations, and cluster assignments are stable. The final clustering forms three distinct groups, primarily separated by flipper length with bill length refining boundaries within clusters.

### Comparison with scikit-learn implementation

To validate the custom K-Means implementation, the final centroids are compared with those obtained from `scikit-learn`. Each centroid is shown as:

**(Bill Length, Flipper Length)**

| Cluster | Custom Implementation | scikit-learn |
|:--------|:---------------------|:-------------|
| 1 | (38.45, 187.05) | (39.56, 188.14) |
| 2 | (47.63, 216.92) | (48.14, 219.29) |
| 3 | (45.95, 196.73) | (46.50, 201.77) |

The centroid locations are close across implementations. Small differences are expected due to initialization and convergence tolerance, but both methods identify the same overall cluster structure.

#### Within-Cluster Sum of Squares (WCSS)
**Selecting the Number of Clusters (WCSS)**
![Figure 4. Within-Cluster Sum of Squares (WCSS) vs. Number of Clusters ](figures/fig4_wcss.png){#fig4_wcss}

WCSS decreases as the number of clusters increases, which is expected because additional clusters reduce within-group variance. The largest drop occurs between k = 2 and k = 3, after which the curve begins to flatten. This “elbow” suggests that three clusters capture most of the structure in the data without adding unnecessary complexity.

#### Silhouette Score
**Cluster Quality (Silhouette Score)**
![Figure 5. Silhouette Score vs. Number of Clusters](figures/fig5_silhouette.png){#fig5_silhouette}

The silhouette score is highest at k = 2, but remains reasonably strong at k = 3. Because the WCSS elbow occurs at three clusters and the dataset contains three biological species, k = 3 provides a balanced and interpretable solution.

### Evaluation of Cluster Quantity

To select the number of clusters, WCSS and silhouette scores were computed for k = 2 to 7.

| K | WCSS | Silhouette Score |
|---:|------:|----------------:|
| 2 | 20949.79 | 0.612 |
| 3 | 14269.56 | **0.456** |
| 4 | 9587.14  | 0.445 |
| 5 | 7597.61  | 0.410 |
| 6 | 6326.31  | 0.414 |
| 7 | 6030.08  | 0.370 |

Although the silhouette score is highest at k = 2, this solution collapses two biologically distinct groups into a single cluster. The WCSS curve shows a clear elbow at **k = 3**, indicating substantial variance reduction when moving from 2 to 3 clusters. 

Because three clusters preserve meaningful morphological distinctions while still maintaining reasonable separation, **k = 3** provides a more interpretable segmentation.

### Final Clustering Result (k = 3)
![Figure 6. K-Means clustering result (k = 3)](figures/fig6_kmeans_k3.png){#fig6_kmeans_k3}

With k = 3, the algorithm separates the data into three distinct groups. The upper cluster captures penguins with the longest flippers and bills, the lower-left cluster represents shorter measurements, and the middle cluster occupies the intermediate range. Centroids (black markers) lie near the center of each group, indicating stable cluster formation.

-----

## Interpretation

The three clusters differ primarily along flipper length. One group shows substantially shorter flippers and bills, another shows the longest measurements, and the third occupies the intermediate range. 

Centroid values indicate that flipper length drives most of the separation, with differences exceeding 20–30 mm between groups. Cluster sizes are reasonably balanced, suggesting the segmentation is not dominated by outliers.