{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Poisson Regression Examples\"\n",
        "format: html\n",
        "author: \"Tweety\"\n",
        "date: today\n",
        "callout-appearance: minimal # this hides the blue \"i\" icon on .callout-notes\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Blueprinty Case Study\n",
        "\n",
        "### Introduction\n",
        "\n",
        "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty's software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty's software and after using it. Unfortunately, such data is not available. \n",
        "\n",
        "However, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm's number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty's software. The marketing team would like to use this data to make the claim that firms using Blueprinty's software are more successful in getting their patent applications approved.\n",
        "\n",
        "\n",
        "### Data\n"
      ],
      "id": "c10865e7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "#| echo: false\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "3f5f6b78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Read the data \n",
        "df = pd.read_csv('blueprinty.csv')\n",
        "\n",
        "# Check structure of the data\n",
        "df.head()"
      ],
      "id": "2df17b26",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate mean number of patents for each group (assuming 'iscustomer' is the same as 'uses_blueprinty')\n",
        "mean_patents = df.groupby('iscustomer')['patents'].mean().reset_index(name='MeanPatents')\n",
        "# Print the results\n",
        "print(mean_patents)"
      ],
      "id": "6f2c527a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Plot histograms to compare number of patents\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=df, x='patents', hue='iscustomer', multiple='dodge', binwidth=1)\n",
        "plt.title('Distribution of Patents by Usage of Blueprinty Software')\n",
        "plt.xlabel('Number of Patents')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend(title='Uses Blueprinty')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "1c3236c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The histogram of patent counts shows a right-skewed distribution, which is expected for count data like the number of patents. Firms using Blueprinty’s software tend to have a distribution that is slightly shifted to the right, indicating they may be more likely to have higher patent counts.\n",
        "\n",
        "When comparing group means, firms that use Blueprinty’s software have an average of approximately 4 patents, compared to 3.6 patents for non-users. While this difference is modest, it does suggest a potential positive association between using the software and patenting success.\n",
        "\n",
        "However, this visual and descriptive comparison alone is not enough to establish a causal relationship. Further statistical analysis — such as a Poisson regression or a formal hypothesis test — is needed to determine whether the observed difference is statistically and practically significant, controlling for other variables like firm age and region. \n",
        "\n",
        "Blueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n"
      ],
      "id": "6b02ce84"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Group summary statistics for age\n",
        "age_summary = df.groupby('iscustomer')['age'].describe()\n",
        "print(\"\\nAge Summary by Customer Status:\")\n",
        "age_summary"
      ],
      "id": "8557256c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Cross-tabulation of region by customer status\n",
        "region_counts = pd.crosstab(df['region'], df['iscustomer'], margins=True)\n",
        "print(\"\\nRegion Distribution by Customer Status:\")\n",
        "region_counts"
      ],
      "id": "259ea107",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------\n",
        "\n",
        "### Estimation of Simple Poisson Model\n",
        "\n",
        "We are interested in modeling the number of patents awarded to each engineering firm over a fixed 5-year period. Since this outcome is a non-negative count variable, the Poisson distribution is a natural choice. It is well-suited for modeling events that occur independently and randomly over time or space.\n",
        "\n",
        "We begin by estimating a simple Poisson model using Maximum Likelihood Estimation (MLE). Let:\n",
        "Y \\sim \\text{Poisson}(\\lambda) where \\lambda is the expected number of patents for a firm.\n",
        "\n",
        "The probability mass function of the Poisson distribution is:\n",
        "f(Y \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^Y}{Y!}\n",
        "\n",
        "Given n independent observations y_1, y_2, \\ldots, y_n, the log-likelihood function is:\n",
        "\n",
        "$$\n",
        "\\ell(\\lambda \\mid y_1, \\ldots, y_n) = -n\\lambda + \\left( \\sum_{i=1}^n y_i \\right) \\log \\lambda - \\sum_{i=1}^n \\log(y_i!)\n",
        "$$\n",
        "\n",
        "This expression captures the likelihood of observing the data as a function of \\lambda, which we estimate by maximizing \\ell(\\lambda).\n"
      ],
      "id": "a6279693"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy.special import gammaln  \n",
        "\n",
        "def poisson_loglikelihood(lmbda, Y):\n",
        "    \"\"\"\n",
        "    Computes the log-likelihood of a Poisson model.\n",
        "    \n",
        "    Parameters:\n",
        "    - lmbda: scalar or array-like (same length as Y), expected rate parameter(s)\n",
        "    - Y: array-like, observed count data\n",
        "\n",
        "    Returns:\n",
        "    - log-likelihood value (scalar)\n",
        "    \"\"\"\n",
        "    lmbda = np.asarray(lmbda)\n",
        "    Y = np.asarray(Y)\n",
        "    \n",
        "    # Ensure shape compatibility\n",
        "    if np.isscalar(lmbda):\n",
        "        lmbda = np.full_like(Y, lmbda, dtype=np.float64)\n",
        "    \n",
        "    # Compute log-likelihood\n",
        "    loglik = np.sum(-lmbda + Y * np.log(lmbda) - gammaln(Y + 1))\n",
        "    return loglik"
      ],
      "id": "8cb0a8ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('blueprinty.csv')\n",
        "Y = df['patents'].values  # observed count data\n",
        "# Evaluate log-likelihood over a range of lambda values\n",
        "lambda_values = np.linspace(0.1, 10, 200)  # avoid zero to prevent log(0)\n",
        "loglik_values = [poisson_loglikelihood(lmb, Y) for lmb in lambda_values]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(lambda_values, loglik_values, label='Log-Likelihood')\n",
        "plt.axvline(np.mean(Y), color='red', linestyle='--', label='Sample Mean (MLE)')\n",
        "plt.title('Poisson Log-Likelihood vs. Lambda')\n",
        "plt.xlabel('Lambda')\n",
        "plt.ylabel('Log-Likelihood')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "c6fe5e5b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To estimate the Poisson rate parameter \\lambda, we use Maximum Likelihood Estimation (MLE). The log-likelihood function for a sample y_1, y_2, \\ldots, y_n drawn independently from a Poisson distribution is:\n",
        "\n",
        "$$\n",
        "\\ell(\\lambda) = -n\\lambda + \\left(\\sum_{i=1}^n y_i\\right) \\log \\lambda - \\sum_{i=1}^n \\log(y_i!)\n",
        "$$\n",
        "\n",
        "To find the value of \\lambda that maximizes this likelihood, we take the first derivative with respect to \\lambda:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\ell}{\\partial \\lambda} = -n + \\frac{\\sum_{i=1}^n y_i}{\\lambda}\n",
        "$$\n",
        "\n",
        "Setting the derivative equal to zero gives the critical point:\n",
        "\n",
        "$$\n",
        "-n + \\frac{\\sum_{i=1}^n y_i}{\\lambda} = 0\n",
        "$$\n",
        "\n",
        "Solving for \\lambda, we obtain:\n",
        "\n",
        "$$\n",
        "\\lambda = \\frac{\\sum_{i=1}^n y_i}{n}\n",
        "$$\n",
        "\n",
        "Thus, the maximum likelihood estimator (MLE) for \\lambda is the sample mean, \\overline{y}:\n",
        "\n",
        "$$\n",
        "\\lambda_{\\text{MLE}} = \\overline{y}\n",
        "$$\n",
        "\n",
        "This result aligns with our intuition: in a Poisson distribution, the mean and variance are both equal to \\lambda, so the best estimate for the average rate of occurrence is the observed average in the data.\n"
      ],
      "id": "c85cb987"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy.optimize import minimize\n",
        "from scipy.special import gammaln\n",
        "\n",
        "# Define the negative log-likelihood function\n",
        "def neg_log_likelihood(lmbda, Y):\n",
        "    lmbda = lmbda[0]  # Extract scalar from array\n",
        "    if lmbda <= 0:\n",
        "        return np.inf\n",
        "    return -np.sum(-lmbda + Y * np.log(lmbda) - gammaln(Y + 1))\n",
        "# Initial guess (sample mean)\n",
        "initial_lambda = np.array([np.mean(Y)])\n",
        "# Perform the optimization\n",
        "result = minimize(fun=neg_log_likelihood, x0=initial_lambda, args=(Y,), method='BFGS')\n",
        "# Extract results\n",
        "lambda_mle = result.x[0]\n",
        "# Print the MLE\n",
        "print(f\"The MLE of lambda is: {lambda_mle:.4f}\")"
      ],
      "id": "f0fc8bf0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------\n",
        "\n",
        "### Estimation of Poisson Regression Model\n",
        "\n",
        "Next, we extend our simple Poisson model to a Poisson Regression Model such that $Y_i = \\text{Poisson}(\\lambda_i)$ where $\\lambda_i = \\exp(X_i'\\beta)$. The interpretation is that the success rate of patent awards is not constant across all firms ($\\lambda$) but rather is a function of firm characteristics $X_i$. Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n"
      ],
      "id": "2a5dccde"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def poisson_regression_neg_loglikelihood(beta, Y, X):\n",
        "    \"\"\"\n",
        "    Computes the negative log-likelihood for Poisson regression.\n",
        "    \n",
        "    Parameters:\n",
        "    - beta: array-like, shape (p,), model coefficients\n",
        "    - Y: array-like, shape (n,), observed counts\n",
        "    - X: array-like, shape (n, p), design matrix of covariates\n",
        "    \n",
        "    Returns:\n",
        "    - Negative log-likelihood (scalar)\n",
        "    \"\"\"\n",
        "    \n",
        "    beta = np.asarray(beta)\n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)    \n",
        "    # Compute lambda_i = exp(X_i^T * beta)\n",
        "    lambda_ = np.exp(X @ beta)    \n",
        "    # Compute log-likelihood\n",
        "    log_likelihood = np.sum(Y * np.log(lambda_) - lambda_ - gammaln(Y + 1))   \n",
        "    return -log_likelihood  "
      ],
      "id": "a4b134e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Create covariates\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import minimize\n",
        "from scipy.special import gammaln\n",
        "from patsy import dmatrix\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"blueprinty.csv\")\n",
        "\n",
        "def poisson_neg_loglikelihood(beta, Y, X):\n",
        "    beta = np.asarray(beta)\n",
        "    lin_pred = X @ beta\n",
        "    lin_pred = np.clip(lin_pred, -20, 20)  # clip log-lambda to a reasonable range\n",
        "    lambda_ = np.exp(lin_pred)\n",
        "    log_likelihood = np.sum(Y * np.log(lambda_) - lambda_ - gammaln(Y + 1))\n",
        "    return -log_likelihood\n",
        "\n",
        "# Create design matrix X using R-style formula\n",
        "# This automatically includes an intercept and handles categorical encoding for 'region'\n",
        "X = dmatrix(\"~ age + I(age**2) + C(region) + iscustomer\", data=df, return_type='dataframe')\n",
        "X_matrix = X.values  # Convert to NumPy array\n",
        "\n",
        "# Response variable\n",
        "Y = df['patents'].values.astype(float)\n",
        "\n",
        "# Define the negative log-likelihood function for Poisson regression\n",
        "def poisson_neg_loglikelihood(beta, Y, X):\n",
        "    beta = np.asarray(beta)\n",
        "    lambda_ = np.exp(X @ beta)\n",
        "    log_likelihood = np.sum(Y * np.log(lambda_) - lambda_ - gammaln(Y + 1))\n",
        "    return -log_likelihood\n",
        "\n",
        "# Initial guess for beta\n",
        "initial_beta = np.zeros(X_matrix.shape[1])\n",
        "\n",
        "# Run optimization\n",
        "result = minimize(fun=poisson_neg_loglikelihood,\n",
        "                  x0=initial_beta,\n",
        "                  args=(Y, X_matrix),\n",
        "                  method='BFGS',\n",
        "                  options={'disp': True})\n",
        "\n",
        "# Extract beta estimates\n",
        "beta_estimates = result.x\n",
        "\n",
        "# Estimate covariance matrix from the inverse Hessian\n",
        "cov_matrix = result.hess_inv\n",
        "standard_errors = np.sqrt(np.diag(cov_matrix))\n",
        "\n",
        "# Create results table\n",
        "results_df = pd.DataFrame({\n",
        "    'Estimate': beta_estimates,\n",
        "    'StdError': standard_errors\n",
        "}, index=X.design_info.column_names)\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nPoisson Regression Coefficients and Standard Errors:\")\n",
        "results_df.round(4)"
      ],
      "id": "bffc85c9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import statsmodels.api as sm"
      ],
      "id": "cc45e04e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.display import display\n",
        "\n",
        "# Rename columns to match your desired output\n",
        "results_df.columns = [\"Estimate\", \"Standard Error\"]\n",
        "\n",
        "# Display nicely with caption\n",
        "display(results_df.style.set_caption(\"Estimated Coefficients and Standard Errors for Poisson Regression Model\")\n",
        "                        .set_properties(**{'text-align': 'center'}))"
      ],
      "id": "d215a636",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The estimated coefficient for iscustomer is 0.5539, suggesting that firms using Blueprinty’s software have a higher expected number of patents. Since Poisson regression models the log of expected counts, we exponentiate the coefficient to interpret it on the original scale: e^{0.5539} \\approx 1.74\n",
        "\n",
        "This implies that, holding age and region constant, Blueprinty customers are expected to receive 74% more patents than non-customers. However, the magnitude of the coefficients for age (38.02) and age² (1033.54) is unusually large and likely reflects scaling issues. This suggests the model may benefit from centering or standardizing the age variable. Finally, the fact that all standard errors are reported as 1.000 raises a concern: it’s likely that results_df was not constructed from actual model output and should be validated to ensure correct inference.\n"
      ],
      "id": "ddaabc68"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Assuming 'df' is your original DataFrame\n",
        "df['age_squared'] = df['age'] ** 2\n",
        "\n",
        "# Create dummy variables for region (drop one to avoid multicollinearity)\n",
        "X = df[['age', 'age_squared', 'region', 'iscustomer']]\n",
        "X = pd.get_dummies(X, columns=['region'], drop_first=True)\n",
        "\n",
        "# Ensure 'iscustomer' is numeric (0/1)\n",
        "X['iscustomer'] = X['iscustomer'].astype(int)\n",
        "\n",
        "# Add intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Define target\n",
        "Y = df['patents']"
      ],
      "id": "71833602",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Convert boolean dummy columns to integers (0/1)\n",
        "for col in X.select_dtypes(include='bool').columns:\n",
        "    X[col] = X[col].astype(int)\n",
        "\n",
        "# Now fit the model\n",
        "model = sm.GLM(Y, X, family=sm.families.Poisson()).fit()\n",
        "print(model.summary())"
      ],
      "id": "a38d6959",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Poisson regression results provide strong evidence that using Blueprinty’s software is associated with increased patenting activity among engineering firms. Firms that use the software are expected to produce approximately 23% more patents over a five-year period, even after accounting for firm age and regional location. This finding supports the claim that Blueprinty’s software contributes positively to patent success.\n"
      ],
      "id": "7e287d48"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Extract coefficient summary from the fitted Poisson model\n",
        "summary_table = model.summary2().tables[1]\n",
        "\n",
        "# Optionally round and rename columns\n",
        "summary_table = model.summary2().tables[1]\n",
        "summary_table = summary_table.rename(columns={\n",
        "    \"Coef.\": \"Estimate\",\n",
        "    \"Std.Err.\": \"Std. Error\",\n",
        "    \"z\": \"z value\",\n",
        "    \"P>|z|\": \"Pr(>|z|)\"\n",
        "}).round(4)\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(summary_table.to_html(index=True)))"
      ],
      "id": "da301550",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Poisson regression analysis provides clear evidence that the use of Blueprinty’s software is significantly associated with higher patent output among engineering firms. The coefficient for iscustomer (0.2076, p < 0.001) suggests that firms using Blueprinty’s tools are expected to produce approximately 23% more patents, holding other factors constant. This finding offers strong empirical support for the claim that Blueprinty’s software contributes to improved patenting outcomes.\n",
        "\n",
        "Firm age is also an important predictor. The positive coefficient for age and the negative coefficient for age squared indicate a nonlinear relationship: patent activity increases as firms mature but eventually slows down—reflecting a typical lifecycle pattern of innovation intensity.\n",
        "\n",
        "In contrast, the analysis finds no statistically significant differences across regions, suggesting that regional location does not meaningfully influence patent success once firm-level factors are considered.\n",
        "\n",
        "\n",
        "### Conclusion\n",
        "Overall, these findings reinforce the value of Blueprinty’s software as a meaningful contributor to patent productivity. At the same time, they highlight the role of firm maturity in shaping innovation outcomes. While regional variation appears limited, the analysis underscores the importance of targeting firms at the right stage of development and aligning product value with their innovation capacity. These insights can guide Blueprinty’s strategic messaging and outreach efforts, particularly when engaging established firms seeking to strengthen their patent portfolios.\n",
        "\n",
        "## AirBnB Case Study\n",
        "\n",
        "### Introduction\n",
        "\n",
        "AirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City.  The data include the following variables:\n",
        "\n",
        ":::: {.callout-note collapse=\"true\"}\n",
        "### Variable Definitions\n",
        "\n",
        "    - `id` = unique ID number for each unit\n",
        "    - `last_scraped` = date when information scraped\n",
        "    - `host_since` = date when host first listed the unit on Airbnb\n",
        "    - `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n",
        "    - `room_type` = Entire home/apt., Private room, or Shared room\n",
        "    - `bathrooms` = number of bathrooms\n",
        "    - `bedrooms` = number of bedrooms\n",
        "    - `price` = price per night (dollars)\n",
        "    - `number_of_reviews` = number of reviews for the unit on Airbnb\n",
        "    - `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n",
        "    - `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n",
        "    - `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n",
        "    - `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n",
        "\n",
        "::::\n",
        "\n",
        "### Data\n"
      ],
      "id": "5b695db9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "airbnb_data = pd.read_csv(\"airbnb.csv\")\n",
        "missing_values = airbnb_data.isna().sum()\n",
        "missing_values\n",
        "\n",
        "# Drop rows with missing values in critical columns\n",
        "critical_columns = [\n",
        "    'bedrooms', 'bathrooms', 'price', 'number_of_reviews',\n",
        "    'review_scores_cleanliness', 'review_scores_location', 'review_scores_value'\n",
        "]\n",
        "airbnb_data = airbnb_data.dropna(subset=critical_columns)\n",
        "\n",
        "print(airbnb_data.describe(include='all'))\n",
        "print(airbnb_data.info())      "
      ],
      "id": "61890ff1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Descriptive\n"
      ],
      "id": "65ebe224"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Distribution of Price\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(airbnb_data['price'], bins=30, kde=False)\n",
        "plt.title(\"Distribution of Prices\")\n",
        "plt.xlabel(\"Price\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# Distribution of Number of Reviews\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(airbnb_data['number_of_reviews'], bins=30)\n",
        "plt.title(\"Distribution of Number of Reviews\")\n",
        "plt.xlabel(\"Number of Reviews\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# Distribution of Bedrooms\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(airbnb_data['bedrooms'], bins=10)\n",
        "plt.title(\"Distribution of Bedrooms\")\n",
        "plt.xlabel(\"Number of Bedrooms\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# Distribution of Bathrooms\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(airbnb_data['bathrooms'], bins=10)\n",
        "plt.title(\"Distribution of Bathrooms\")\n",
        "plt.xlabel(\"Number of Bathrooms\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "id": "58368e68",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=airbnb_data, x='price', y='number_of_reviews', alpha=0.5, color='blue')\n",
        "plt.title(\"Price vs. Number of Reviews\")\n",
        "plt.xlabel(\"Price ($)\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.show()"
      ],
      "id": "f01c2476",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=airbnb_data, x='bedrooms', y='number_of_reviews')\n",
        "plt.title(\"Bedrooms vs. Number of Reviews\")\n",
        "plt.xlabel(\"Bedrooms\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.show()"
      ],
      "id": "6be1de6b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(data=airbnb_data, x='instant_bookable', palette='pastel')\n",
        "plt.title(\"Effect of Instant Bookable Feature on Listing Counts\")\n",
        "plt.xlabel(\"Instant Bookable\")\n",
        "plt.ylabel(\"Count of Listings\")\n",
        "plt.show()"
      ],
      "id": "2401fe3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----\n",
        "\n",
        "### Analysis\n"
      ],
      "id": "c81efcf4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Fit the Poisson regression model\n",
        "poisson_model = smf.glm(\n",
        "    formula=\"number_of_reviews ~ bedrooms + bathrooms + price + review_scores_cleanliness + review_scores_location + review_scores_value + instant_bookable\",\n",
        "    data=airbnb_data,\n",
        "    family=sm.families.Poisson()\n",
        ").fit()\n",
        "\n",
        "# Display the summary\n",
        "print(poisson_model.summary())"
      ],
      "id": "e54a6756",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Poisson regression model reveals key drivers of Airbnb review counts. The intercept (3.543) sets a baseline log count, though it’s mainly a mathematical reference point.\n",
        "\n",
        "Bedrooms: Each additional bedroom increases expected reviews by ~8% (exp(0.0782)), suggesting that larger properties engage more guests.\n",
        "\n",
        "Bathrooms: Surprisingly, more bathrooms reduce reviews by ~12% (exp(-0.1286)), which may reflect less demand or review activity in niche or high-end listings.\n",
        "\n",
        "Pricing: Price has no statistically significant effect on review count (p = 0.126), indicating that, within this dataset, pricing is not a major engagement factor.\n",
        "\n",
        "Guest Ratings: Cleanliness significantly boosts reviews—each additional point corresponds to a ~12% increase, highlighting its importance. Location and Value scores are negatively associated with reviews, which may reflect confounding or lower guest motivation to review when expectations are fully met.\n",
        "\n",
        "Booking Convenience: Instant Bookable listings receive ~39% more reviews (exp(0.3319)), showing the value of booking ease in driving guest interaction.\n",
        "\n",
        "Model Fit: While the model fits reasonably well (Pseudo R² = 0.55), the high Pearson chi-squared suggests potential overdispersion—worth addressing with a Negative Binomial model.\n"
      ],
      "id": "ed68acfa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit Negative Binomial regression model\n",
        "nb_model = smf.glm(\n",
        "    formula=\"number_of_reviews ~ bedrooms + bathrooms + price + review_scores_cleanliness + review_scores_location + review_scores_value + instant_bookable\",\n",
        "    data=airbnb_data,\n",
        "    family=sm.families.NegativeBinomial()\n",
        ").fit()\n",
        "\n",
        "# Display summary\n",
        "print(nb_model.summary())"
      ],
      "id": "0dd197b9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Negative Binomial regression model reveals clear patterns in what drives Airbnb review counts, addressing overdispersion present in the Poisson model. The model confirms that listing features and guest experience ratings significantly influence engagement.\n",
        "\n",
        "Key Drivers: Bedrooms: Each additional bedroom increases expected reviews by ~7.7% (exp(0.0741)), likely reflecting higher capacity and group travel.\n",
        "\n",
        "Bathrooms: More bathrooms are associated with fewer reviews (~10.8% decrease), though the reason is unclear and may relate to unobserved listing characteristics.\n",
        "\n",
        "Price: Has no significant effect, suggesting review likelihood is not sensitive to rental cost within the dataset’s range.\n",
        "\n",
        "Guest Experience Ratings: Cleanliness: Strongly predictive—each point increase leads to ~21.7% more reviews, highlighting its role in satisfaction.\n",
        "\n",
        "Location & Value: Unexpectedly, higher scores correlate with fewer reviews. This may reflect a lower urgency to leave feedback when expectations are met.\n",
        "\n",
        "Instant Bookability:Listings with this feature see ~38.5% more reviews (exp(0.3263)), underlining the value of booking convenience.\n",
        "\n",
        "Model Fit: The model’s lower deviance and log-likelihood indicate improved fit over Poisson, and confirm the presence of overdispersion. Still, a low pseudo R² (0.044) suggests many unobserved factors influence reviews.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "In conclusion, this analysis provides actionable insights for Airbnb hosts seeking to increase guest reviews. Practical features—such as offering more bedrooms and enabling instant booking—are associated with higher review counts, likely due to their appeal to larger groups and convenience-focused travelers. Cleanliness stands out as the most influential factor, reinforcing its critical role in guest satisfaction and review likelihood.\n",
        "\n",
        "While review scores for location and value also play a role, their effects are more nuanced and may reflect complex guest expectations. These findings suggest that while enhancing key amenities is important, understanding guest behavior remains an area for further exploration. Overall, hosts can benefit by focusing on what matters most: delivering clean, accessible, and well-equipped stays that encourage positive engagement."
      ],
      "id": "fb340d8e"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "mgta495",
      "language": "python",
      "display_name": "Python (mgta495)",
      "path": "/Users/qqtweety/Library/Jupyter/kernels/mgta495"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}